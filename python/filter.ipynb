{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44c41581-b03a-45a0-bc1c-e26410fa3f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Filter\" We are selecting the required rows from a dataframe syntax:dataframe.filter(\"\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25e358cd-2314-4a2b-b20c-aeb9fa8b4cc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+-----+\n|firstname|lastname|country|state|  sal|\n+---------+--------+-------+-----+-----+\n|     raja|  pushpa|    USA|     |30000|\n|    priya|  pushpa|    USA|     |29900|\n|  Karthik|    Subu|    USA|   CA| 6000|\n|    James|   Smith|    USA|   FL|20000|\n|   Martin|   Jones|    USA|   CA| 3000|\n|      Sam|Anderson|     UK|  LND| 8000|\n|    Maria| Patrick|     UK|  MCR| 7000|\n|    Robet|   Bevon|     UK|  LND| 3500|\n|    Maria|Anderson|     UK|  MCR| 3000|\n+---------+--------+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "staticlist = [(\" raja\", \"pushpa\", \"USA\",\"\",30000),\n",
    "            (\" priya\", \"pushpa\", \"USA\",\"\",29900),\n",
    "            (\" Karthik\", \"Subu\", \"USA\",\"CA\",6000),\n",
    "            (\" James\", \"Smith\", \"USA\",\"FL\",20000),\n",
    "            (\"Martin\", \"Jones\", \"USA\",\"CA\",3000),\n",
    "            (\"Sam\", \"Anderson\", \"UK\",\"LND\",8000),\n",
    "            (\"Maria\", \"Patrick\", \"UK\",\"MCR\",7000),\n",
    "            (\"Robet\", \"Bevon\", \"UK\",\"LND\",3500),\n",
    "            (\"Maria\", \"Anderson\", \"UK\",\"MCR\",3000)\n",
    "            ]\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\",\"sal\"]            \n",
    "df = spark.createDataFrame( data = staticlist, schema = columns)\n",
    "df.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0f133b-d3ce-4b18-9835-4ca3a86144da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-------+-----+------+\n|      FirstName|      LastName|Country|State|Salary|\n+---------------+--------------+-------+-----+------+\n|           raja|        pushpa|    USA|     | 30000|\n|          priya|        pushpa|    USA|     | 29900|\n|        Karthik|Subu          |    USA|   CA|  6000|\n|          James|         Smith|    USA|   FL| 20000|\n|         Martin|         Jones|    USA|   CA|  3000|\n|            Sam|      Anderson|     UK|  LND|  8000|\n|          Maria|       Patrick|     UK|  MCR|  7000|\n|          Robet| Bevon        |    UK |  LND|  3500|\n|          Maria|   Anderson   |     UK|  MCR|  3000|\n+---------------+--------------+-------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "staticlist = [(\" raja\", \"pushpa\", \"USA\",\"\",30000),\n",
    "            (\" priya\", \"pushpa\", \"USA\",\"\",29900),\n",
    "            (\" Karthik\", \"Subu          \", \"USA\",\"CA\",6000),\n",
    "            (\"          James\", \"Smith\", \"USA\",\"FL\",20000),\n",
    "            (\"Martin\", \"Jones\", \"USA\",\"CA\",3000),\n",
    "            (\"Sam\", \"Anderson\", \"UK\",\"LND\",8000),\n",
    "            (\"Maria\", \"Patrick\", \"UK\",\"MCR\",7000),\n",
    "            (\"Robet\", \"Bevon        \", \"UK \",\"LND\",3500),\n",
    "            (\"Maria\", \"Anderson   \", \"UK\",\"MCR\",3000)\n",
    "            ]\n",
    "StructSchema = StructType([\n",
    "                            StructField('FirstName',StringType(),False),\n",
    "                            StructField('LastName',StringType(),True),\n",
    "                            StructField('Country',StringType(),False),\n",
    "                            StructField('State',StringType(),False),\n",
    "                            StructField('Salary',StringType(),False),\n",
    "])\n",
    "df = spark.createDataFrame(data = staticlist, schema = StructSchema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d8d7703-f059-4150-890b-87436be8010f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+------+\n|FirstName|LastName|Country|State|Salary|\n+---------+--------+-------+-----+------+\n|     raja|  pushpa|    USA|     | 30000|\n|    priya|  pushpa|    USA|     | 29900|\n|  Karthik|    Subu|    USA|   CA|  6000|\n|    James|   Smith|    USA|   FL| 20000|\n|      Sam|Anderson|     UK|  LND|  8000|\n|    Maria| Patrick|     UK|  MCR|  7000|\n+---------+--------+-------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#place  a filter where salary is above 5000 #single column filter\n",
    "df_filter1 = df.filter(\"Salary > 5000\")\n",
    "df_filter1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a702834e-0f80-4d59-97cd-459fab1520b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+------+\n|FirstName|LastName|Country|State|Salary|\n+---------+--------+-------+-----+------+\n|      Sam|Anderson|     UK|  LND|  8000|\n|    Maria| Patrick|     UK|  MCR|  7000|\n+---------+--------+-------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#Multiple Column filters\n",
    "#get employees with salary > 5000 and country is UK\n",
    "df_filter1 = df.filter(\"Salary > 5000 AND Country = 'UK'\")\n",
    "df_filter1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4a2909b-c053-4c40-8901-d6da33da44bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+------+\n|FirstName|LastName|Country|State|Salary|\n+---------+--------+-------+-----+------+\n|     raja|  pushpa|    USA|     | 30000|\n|    priya|  pushpa|    USA|     | 29900|\n|  Karthik|    Subu|    USA|   CA|  6000|\n|    James|   Smith|    USA|   FL| 20000|\n|      Sam|Anderson|     UK|  LND|  8000|\n|    Maria| Patrick|     UK|  MCR|  7000|\n+---------+--------+-------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#option2 using dataframe method\n",
    "\n",
    "df_filter2 = df.filter(df.Salary > 5000)\n",
    "df_filter2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b613ef32-06db-4840-a768-3eda7c90100c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+------+\n|FirstName|LastName|Country|State|Salary|\n+---------+--------+-------+-----+------+\n|      Sam|Anderson|     UK|  LND|  8000|\n|    Maria| Patrick|     UK|  MCR|  7000|\n+---------+--------+-------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#option2: Multiple Column filters\n",
    "# when using dataframe AND will be replaces with \"&\" symbol, OR will be replace with \"|\" symbol and  \"=\" will be replaced with \"==\" symbol\n",
    "df_filter2 = df.filter((df.Salary > 5000) & (df.Country == 'UK'))\n",
    "df_filter2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dac0c6d-3fa8-4f86-9bb4-c030de42c42d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+------+\n|FirstName|LastName|Country|State|Salary|\n+---------+--------+-------+-----+------+\n|     raja|  pushpa|    USA|     | 30000|\n|    priya|  pushpa|    USA|     | 29900|\n|      Sam|Anderson|     UK|  LND|  8000|\n+---------+--------+-------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Multiple colums and multiple conditions\n",
    "# If country is US then salary > 20000, If Country is not US then salary > 5000\n",
    "\n",
    "df_filter3 = df.filter(\n",
    "    ((df.Country == 'USA') & (df.Salary > 20000))\n",
    "    |\n",
    "    ((df.Country != 'USA') & (df.Salary > 7000))\n",
    ")\n",
    "\n",
    "df_filter3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "573917dc-0a11-484a-ae9d-2c30080d6777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+------+---------+---------+---------+\n|FirstName|LastName|Country|State|Salary|UpperCase|LowerCase|TitleCase|\n+---------+--------+-------+-----+------+---------+---------+---------+\n|     raja|  pushpa|    USA|     | 30000|     RAJA|     raja|     Raja|\n|    priya|  pushpa|    USA|     | 29900|    PRIYA|    priya|    Priya|\n|  Karthik|    Subu|    USA|   CA|  6000|  KARTHIK|  karthik|  Karthik|\n|    James|   Smith|    USA|   FL| 20000|    JAMES|    james|    James|\n|   Martin|   Jones|    USA|   CA|  3000|   MARTIN|   martin|   Martin|\n|      Sam|Anderson|     UK|  LND|  8000|      SAM|      sam|      Sam|\n|    Maria| Patrick|     UK|  MCR|  7000|    MARIA|    maria|    Maria|\n|    Robet|   Bevon|     UK|  LND|  3500|    ROBET|    robet|    Robet|\n|    Maria|Anderson|     UK|  MCR|  3000|    MARIA|    maria|    Maria|\n+---------+--------+-------+-----+------+---------+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Get the Upper case, lower case and title case fro any string\n",
    "# you can apply these functions inside the withColumn method to apply the required transformations\n",
    "\n",
    "# get the upper case for dataframe which using now\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "df2 = df.withColumn(\"UpperCase\",upper(\"firstname\"))\\\n",
    "       .withColumn(\"LowerCase\",lower(\"firstname\"))\\\n",
    "       .withColumn(\"TitleCase\",initcap(\"firstname\"))    \n",
    "df2.show()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc29d06-2b4f-4e15-bdb4-f6c5c1692981",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-------+-----+------+--------------------+\n|      FirstName|      LastName|Country|State|Salary|           Full_Name|\n+---------------+--------------+-------+-----+------+--------------------+\n|           raja|        pushpa|    USA|     | 30000|         Raja Pushpa|\n|          priya|        pushpa|    USA|     | 29900|        Priya Pushpa|\n|        Karthik|Subu          |    USA|   CA|  6000| Karthik Subu    ...|\n|          James|         Smith|    USA|   FL| 20000|          James S...|\n|         Martin|         Jones|    USA|   CA|  3000|        Martin Jones|\n|            Sam|      Anderson|     UK|  LND|  8000|        Sam Anderson|\n|          Maria|       Patrick|     UK|  MCR|  7000|       Maria Patrick|\n|          Robet| Bevon        |    UK |  LND|  3500| Robet Bevon        |\n|          Maria|   Anderson   |     UK|  MCR|  3000|   Maria Anderson   |\n+---------------+--------------+-------+-----+------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#concat firstname and last name to create a full name\n",
    "#concat(\"col1\",\"col2\",col3..)\n",
    "df2 = df.withColumn(\"Full_Name\",concat(initcap(\"firstname\"),lit(\" \"), initcap(\"lastname\")))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "963fdffc-6200-4100-918c-4177b0488758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# https://www.databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "190f227c-9385-46ce-a1be-a0a03a411732",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-------+-----+------+-------------+\n|      FirstName|      LastName|Country|State|Salary|TrimedVersion|\n+---------------+--------------+-------+-----+------+-------------+\n|           raja|        pushpa|    USA|     | 30000|       pushpa|\n|          priya|        pushpa|    USA|     | 29900|       pushpa|\n|        Karthik|Subu          |    USA|   CA|  6000|         Subu|\n|          James|         Smith|    USA|   FL| 20000|        Smith|\n|         Martin|         Jones|    USA|   CA|  3000|        Jones|\n|            Sam|      Anderson|     UK|  LND|  8000|     Anderson|\n|          Maria|       Patrick|     UK|  MCR|  7000|      Patrick|\n|          Robet| Bevon        |    UK |  LND|  3500|        Bevon|\n|          Maria|   Anderson   |     UK|  MCR|  3000|     Anderson|\n+---------------+--------------+-------+-----+------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# remmoving ladig and triling speces\n",
    "# trim function will remove leading and trailing speacs from any string\n",
    "df3 =  df. withColumn(\"TrimedVersion\",trim(\"lastname\"))\n",
    "df3.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "filter",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}